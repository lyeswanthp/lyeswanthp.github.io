<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multimodal RAG for Document Understanding | Lovely Yeswanth P</title>
    <link rel="stylesheet" href="../styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        .project-detail { max-width: 800px; margin: 100px auto 50px; padding: 0 1.5rem; }
        .back-link { display: inline-block; color: #6366f1; text-decoration: none; margin-bottom: 2rem; }
        .back-link:hover { text-decoration: underline; }
        .project-header { margin-bottom: 3rem; }
        .project-header h1 { font-size: 2.5rem; margin-bottom: 1rem; }
        .project-meta { display: flex; gap: 1rem; flex-wrap: wrap; margin-bottom: 2rem; }
        .project-meta a { color: #1a1a1a; text-decoration: none; padding: 0.5rem 1rem; background: #f5f5f5; border-radius: 6px; }
        .project-meta a:hover { background: #e5e5e5; }
        .section { margin-bottom: 2.5rem; }
        .section h2 { font-size: 1.5rem; margin-bottom: 1rem; }
        .section p, .section li { color: #666; line-height: 1.8; margin-bottom: 1rem; }
        ul { padding-left: 1.5rem; }
        .tech-list { display: flex; flex-wrap: wrap; gap: 0.5rem; margin-top: 1rem; }
        .tech-tag { padding: 0.5rem 1rem; background: #f5f5f5; border-radius: 6px; font-size: 0.9rem; }
        .metrics { display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 1.5rem; margin: 2rem 0; }
        .metric-box { padding: 1.5rem; background: #f5f5f5; border-radius: 8px; text-align: center; }
        .metric-value { font-size: 2rem; font-weight: 700; color: #6366f1; }
        .metric-label { color: #666; margin-top: 0.5rem; }
    </style>
</head>
<body>
    <div class="project-detail">
        <a href="../index.html#projects" class="back-link">← Back to Projects</a>

        <div class="project-header">
            <h1>Multimodal RAG for Document Understanding</h1>
            <div class="project-meta">
                <a href="https://github.com/lyeswanthp/Multimodal_RAG_for_Document_Understanding" target="_blank">View on GitHub →</a>
            </div>
        </div>

        <div class="section">
            <h2>Overview</h2>
            <p>
                A cutting-edge vision-language RAG system designed to process complex PDFs by converting document pages
                into image patches and embedding them using the ColPali vision-language model. The system stores embeddings
                in Qdrant vector database and integrates DeepSeek Janus-Pro for handling both image and text context,
                enabling natural-language queries over visual documents.
            </p>
        </div>

        <div class="metrics">
            <div class="metric-box">
                <div class="metric-value">85%</div>
                <div class="metric-label">Answer Precision</div>
            </div>
            <div class="metric-box">
                <div class="metric-value">450ms</div>
                <div class="metric-label">Average Latency</div>
            </div>
        </div>

        <div class="section">
            <h2>Key Features</h2>
            <ul>
                <li>Converts PDF pages into image patches for visual understanding</li>
                <li>Uses ColPali embeddings to capture both visual and textual information</li>
                <li>Qdrant vector database for efficient similarity search</li>
                <li>DeepSeek Janus-Pro integration for multimodal query understanding</li>
                <li>Handles complex document layouts, tables, and figures</li>
                <li>Natural language query interface</li>
            </ul>
        </div>

        <div class="section">
            <h2>Technical Approach</h2>
            <p>
                The system leverages state-of-the-art vision-language models to understand documents beyond just text extraction.
                By treating each page as an image and using ColPali's multimodal embeddings, the system can understand spatial
                relationships, visual hierarchies, and graphical elements that traditional text-based RAG systems miss.
            </p>
            <p>
                The Qdrant vector database provides fast similarity search capabilities, while DeepSeek Janus-Pro acts as the
                reasoning engine that can interpret both the retrieved visual context and user queries to generate accurate answers.
            </p>
        </div>

        <div class="section">
            <h2>Technologies Used</h2>
            <div class="tech-list">
                <span class="tech-tag">Python</span>
                <span class="tech-tag">ColPali</span>
                <span class="tech-tag">Qdrant</span>
                <span class="tech-tag">DeepSeek Janus-Pro</span>
                <span class="tech-tag">Vision-Language Models</span>
                <span class="tech-tag">PDF Processing</span>
                <span class="tech-tag">Vector Databases</span>
            </div>
        </div>

        <div class="section">
            <h2>Impact</h2>
            <p>
                This project demonstrates the power of multimodal AI for document understanding, achieving 85% precision
                in answering questions about complex documents while maintaining sub-500ms response times. The system is
                particularly effective for documents with rich visual content like technical papers, reports, and presentations.
            </p>
        </div>
    </div>

    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Lovely Yeswanth Panchumarthi</p>
        </div>
    </footer>
</body>
</html>
